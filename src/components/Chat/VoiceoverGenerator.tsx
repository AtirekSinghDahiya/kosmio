import React, { useState, useEffect, useRef } from 'react';
import { Volume2, Download, X, Loader, Play, Pause, Sparkles, Users } from 'lucide-react';
import { generateVoiceover } from '../../lib/voiceoverService';
import { useToast } from '../../contexts/ToastContext';
import { useTheme } from '../../contexts/ThemeContext';
import { analyzeScript, DialogueLine } from '../../lib/scriptAnalyzer';

interface VoiceoverGeneratorProps {
  onClose: () => void;
  initialText?: string;
}

const VOICE_OPTIONS = [
  { id: '21m00Tcm4TlvDq8ikWAM', name: 'Rachel', description: 'Calm, natural female voice' },
  { id: 'EXAVITQu4vr4xnSDxMaL', name: 'Bella', description: 'Soft, expressive female voice' },
  { id: 'MF3mGyEYCl7XYWbV9V6O', name: 'Elli', description: 'Young, energetic female voice' },
  { id: 'AZnzlk1XvdvUeBnXmlld', name: 'Domi', description: 'Strong, confident female voice' },
  { id: 'TxGEqnHWrfWFTfGW9XjX', name: 'Josh', description: 'Deep, warm male voice' },
  { id: 'VR6AewLTigWG4xSOukaG', name: 'Arnold', description: 'Strong, authoritative male voice' },
  { id: 'pNInz6obpgDQGcFmaJgB', name: 'Adam', description: 'Deep, natural male voice' },
  { id: 'yoZ06aMxZJJ28mfd3POQ', name: 'Sam', description: 'Clear, professional male voice' },
  { id: 'CwhRBWXzGAHq8TQ4Fs17', name: 'Roger', description: 'Mature, confident male voice' },
  { id: 'IKne3meq5aSn9XLyUdCD', name: 'Charlie', description: 'Casual, friendly male voice' },
];

export const VoiceoverGenerator: React.FC<VoiceoverGeneratorProps> = ({ onClose, initialText = '' }) => {
  const { theme } = useTheme();
  const { showToast } = useToast();
  const [text, setText] = useState(initialText);
  const [isGenerating, setIsGenerating] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [hasAutoGenerated, setHasAutoGenerated] = useState(false);
  const [selectedVoice, setSelectedVoice] = useState(VOICE_OPTIONS[0].id);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isDialogue, setIsDialogue] = useState(false);
  const [dialogueLines, setDialogueLines] = useState<DialogueLine[]>([]);
  const [aiSuggestion, setAiSuggestion] = useState<string>('');
  const audioRef = useRef<HTMLAudioElement>(null);

  useEffect(() => {
    if (initialText && !hasAutoGenerated) {
      setHasAutoGenerated(true);
      analyzeAndPrepare(initialText);
    }
  }, [initialText, hasAutoGenerated]);

  useEffect(() => {
    return () => {
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [audioUrl]);

  const analyzeAndPrepare = async (rawText: string) => {
    setIsAnalyzing(true);
    setAiSuggestion('');

    try {
      const analysis = await analyzeScript(rawText);

      setText(analysis.cleanedText);
      setIsDialogue(analysis.isDialogue);
      setDialogueLines(analysis.dialogueLines);

      if (analysis.suggestedVoice) {
        setSelectedVoice(analysis.suggestedVoice.id);
        setAiSuggestion(`AI suggests: ${analysis.suggestedVoice.name} (${analysis.suggestedVoice.reason})`);
      }

      if (analysis.isDialogue && analysis.dialogueLines.length > 0) {
        showToast('info', 'Dialogue Detected', `Found ${analysis.dialogueLines.length} lines with multiple speakers`);
        setTimeout(() => handleGenerateDialogue(), 500);
      } else {
        setTimeout(() => handleGenerate(analysis.cleanedText), 500);
      }
    } catch (error) {
      console.error('Script analysis failed:', error);
      setText(rawText);
      setTimeout(() => handleGenerate(rawText), 500);
    } finally {
      setIsAnalyzing(false);
    }
  };

  const handleGenerateDialogue = async () => {
    if (dialogueLines.length === 0) return;

    setIsGenerating(true);
    const audioChunks: Blob[] = [];

    try {
      showToast('info', 'Generating Dialogue', `Creating ${dialogueLines.length} voice lines...`);

      for (const line of dialogueLines) {
        const blob = await generateVoiceover({
          text: line.text,
          voiceId: line.voiceId
        });
        audioChunks.push(blob);
      }

      const combinedBlob = new Blob(audioChunks, { type: 'audio/mpeg' });

      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }

      const url = URL.createObjectURL(combinedBlob);
      setAudioBlob(combinedBlob);
      setAudioUrl(url);
      showToast('success', 'Dialogue Ready!', 'Multi-voice conversation generated successfully');
    } catch (error: any) {
      console.error('Dialogue generation error:', error);
      showToast('error', 'Generation Failed', error.message || 'Unable to generate dialogue');
    } finally {
      setIsGenerating(false);
    }
  };

  const handleGenerate = async (customText?: string) => {
    const textToUse = customText || text.trim();

    if (!textToUse) {
      showToast('warning', 'Enter text', 'Please enter the text you want to convert to speech');
      return;
    }

    if (isGenerating) {
      console.log('ðŸš« Generation already in progress');
      return;
    }

    console.log('ðŸŽ¤ Starting voiceover generation:', textToUse);
    setIsGenerating(true);

    try {
      showToast('info', 'Generating Voice', 'Creating your voiceover with ElevenLabs...');

      const blob = await generateVoiceover({
        text: textToUse,
        voiceId: selectedVoice
      });

      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }

      const url = URL.createObjectURL(blob);
      setAudioBlob(blob);
      setAudioUrl(url);
      showToast('success', 'Voiceover Ready!', 'Your audio has been generated successfully');
    } catch (error: any) {
      console.error('Voiceover generation error:', error);
      showToast('error', 'Generation Failed', error.message || 'Unable to generate voiceover. Please try again.');
    } finally {
      setIsGenerating(false);
    }
  };

  const togglePlayPause = () => {
    if (!audioRef.current || !audioUrl) return;

    if (isPlaying) {
      audioRef.current.pause();
      setIsPlaying(false);
    } else {
      audioRef.current.play();
      setIsPlaying(true);
    }
  };

  const handleDownload = () => {
    if (!audioBlob) return;

    const url = URL.createObjectURL(audioBlob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'voiceover.mp3';
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
    showToast('success', 'Downloaded', 'Audio file saved successfully');
  };

  return (
    <div className="fixed inset-0 z-50 flex items-center justify-center p-4 bg-black/60 backdrop-blur-sm animate-fade-in">
      <div className={`relative w-full max-w-2xl rounded-2xl shadow-2xl animate-scale-in ${
        theme === 'light'
          ? 'bg-gradient-to-br from-slate-50 via-white to-slate-50 border border-gray-200'
          : 'bg-gradient-to-br from-slate-800 via-slate-700 to-slate-800 border border-white/20'
      }`}>
        <button
          onClick={onClose}
          className="absolute top-4 right-4 p-2 rounded-full hover:bg-white/10 transition-colors group z-10"
        >
          <X className={`w-5 h-5 ${theme === 'light' ? 'text-gray-600 group-hover:text-gray-900' : 'text-gray-400 group-hover:text-white'}`} />
        </button>

        <div className="p-8">
          <div className="flex items-center gap-3 mb-6">
            <div className="p-3 bg-gradient-to-br from-teal-500 to-blue-500 rounded-xl">
              <Volume2 className="w-6 h-6 text-white" />
            </div>
            <div>
              <h2 className={`text-2xl font-bold ${theme === 'light' ? 'text-gray-900' : 'text-white'}`}>AI Voiceover Generator</h2>
              <p className={`text-sm ${theme === 'light' ? 'text-gray-600' : 'text-gray-400'}`}>Convert your text to natural speech</p>
            </div>
          </div>

          <div className="space-y-6">
            {aiSuggestion && (
              <div className="bg-gradient-to-r from-teal-500/10 to-blue-500/10 border border-teal-500/30 rounded-xl p-4 flex items-start gap-3">
                <Sparkles className="w-5 h-5 text-teal-400 mt-0.5 flex-shrink-0" />
                <div>
                  <p className="text-sm text-teal-300 font-medium">{aiSuggestion}</p>
                </div>
              </div>
            )}

            {isDialogue && dialogueLines.length > 0 && (
              <div className="bg-gradient-to-r from-purple-500/10 to-pink-500/10 border border-purple-500/30 rounded-xl p-4">
                <div className="flex items-center gap-2 mb-3">
                  <Users className="w-5 h-5 text-purple-400" />
                  <p className="text-sm font-medium text-purple-300">Multi-Speaker Dialogue Detected</p>
                </div>
                <div className="space-y-2">
                  {dialogueLines.map((line, idx) => (
                    <div key={idx} className="text-sm text-gray-300">
                      <span className="font-semibold text-purple-300">{line.speaker}</span>
                      <span className="text-gray-500 mx-2">({line.voiceName})</span>
                      <span className="text-gray-400">: {line.text}</span>
                    </div>
                  ))}
                </div>
              </div>
            )}

            {!isDialogue && (
              <div>
                <label className="block text-sm font-medium text-gray-300 mb-2">
                  Select Voice
                </label>
                <select
                  value={selectedVoice}
                  onChange={(e) => setSelectedVoice(e.target.value)}
                  className="w-full px-4 py-3 bg-slate-700/50 border border-white/20 rounded-xl text-white focus:outline-none focus:ring-2 focus:ring-teal-500 cursor-pointer"
                  disabled={isAnalyzing || isGenerating}
                >
                  {VOICE_OPTIONS.map((voice) => (
                    <option key={voice.id} value={voice.id} className="bg-gray-800">
                      {voice.name} - {voice.description}
                    </option>
                  ))}
                </select>
              </div>
            )}

            <div>
              <label className="block text-sm font-medium text-gray-300 mb-2">
                Enter Text
              </label>
              <textarea
                value={text}
                onChange={(e) => setText(e.target.value)}
                placeholder="Type or paste the text you want to convert to speech..."
                className="w-full h-40 px-4 py-3 bg-slate-700/50 border border-white/20 rounded-xl text-white placeholder-gray-400 focus:outline-none focus:ring-2 focus:ring-teal-500 resize-none"
                maxLength={5000}
              />
              <div className="flex justify-between items-center mt-2">
                <span className="text-sm text-gray-400">{text.length} / 5000 characters</span>
              </div>
            </div>

            {audioUrl && (
              <div className="bg-slate-700/30 border border-white/20 rounded-xl p-6">
                <audio
                  ref={audioRef}
                  src={audioUrl}
                  onEnded={() => setIsPlaying(false)}
                  className="hidden"
                />
                <div className="flex items-center gap-4">
                  <button
                    onClick={togglePlayPause}
                    className="w-14 h-14 bg-teal-500 hover:bg-teal-600 rounded-full flex items-center justify-center transition-colors"
                  >
                    {isPlaying ? (
                      <Pause className="w-6 h-6 text-white" />
                    ) : (
                      <Play className="w-6 h-6 text-white ml-1" />
                    )}
                  </button>
                  <div className="flex-1">
                    <p className="text-white font-medium mb-1">Generated Voiceover</p>
                    <p className="text-sm text-gray-400">Click play to listen</p>
                  </div>
                </div>
              </div>
            )}

            <div className="flex gap-3">
              <button
                onClick={() => isDialogue ? handleGenerateDialogue() : handleGenerate()}
                disabled={isGenerating || isAnalyzing || !text.trim()}
                className="flex-1 px-6 py-3 bg-gradient-to-r from-teal-500 to-blue-500 hover:from-teal-600 hover:to-blue-600 disabled:from-gray-600 disabled:to-gray-600 text-white rounded-xl font-semibold transition-all disabled:cursor-not-allowed flex items-center justify-center gap-2"
              >
                {isAnalyzing ? (
                  <>
                    <Sparkles className="w-5 h-5 animate-spin" />
                    Analyzing Script...
                  </>
                ) : isGenerating ? (
                  <>
                    <Loader className="w-5 h-5 animate-spin" />
                    Generating...
                  </>
                ) : (
                  <>
                    <Volume2 className="w-5 h-5" />
                    {isDialogue ? 'Generate Dialogue' : 'Generate Voiceover'}
                  </>
                )}
              </button>

              {audioBlob && (
                <button
                  onClick={handleDownload}
                  className="px-6 py-3 bg-white/10 hover:bg-white/20 text-white rounded-xl font-semibold transition-all flex items-center gap-2"
                >
                  <Download className="w-5 h-5" />
                  Download
                </button>
              )}
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};
